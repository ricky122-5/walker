# -*- coding: utf-8 -*-
"""blindsite-FINAL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14jn7-Ot7U1y914URVzI8ead_Q8s9IPxc
"""

import os
import time
import cv2
import numpy as np
from model.yolo_model import YOLO
from time import sleep
from google.cloud import texttospeech
from google.cloud import texttospeech_v1
from playsound import playsound

def readyText(text):
    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'C:/Users/Rikki/Downloads/Computer-Vision-with-Python/Computer-Vision-with-Python/DATA/blindapp-310321-10ccdaacf88e.json'
    client = texttospeech_v1.TextToSpeechClient()
    #text = 'Hi my name is Ricky'

    synthesis_input = texttospeech_v1.SynthesisInput(text=text)
    voice = texttospeech_v1.VoiceSelectionParams(
    language_code='en',
    ssml_gender=texttospeech_v1.SsmlVoiceGender.MALE
    #name="en-US-Wavenet-J",
    #language_codes='en-US'
    )    
    audio_config = texttospeech_v1.AudioConfig(
        audio_encoding = texttospeech_v1.AudioEncoding.MP3
    )

    response = client.synthesize_speech(
        input = synthesis_input,
        voice = voice,
        audio_config = audio_config
    )

    with open('theaudio.mp3', 'wb') as output:
        output.write(response.audio_content)

    playsound('C:/Users/Rikki/Downloads/Computer-Vision-with-Python/Computer-Vision-with-Python/06-Deep-Learning-Computer-Vision/06-YOLOv3/theaudio.mp3')
    os.remove('C:/Users/Rikki/Downloads/Computer-Vision-with-Python/Computer-Vision-with-Python/06-Deep-Learning-Computer-Vision/06-YOLOv3/theaudio.mp3')

def process_image(img):
    """Resize, reduce and expand image.

    # Argument:
        img: original image.

    # Returns
        image: ndarray(64, 64, 3), processed image.
    """
    image = cv2.resize(img, (416, 416),
                       interpolation=cv2.INTER_CUBIC)

                       
    image = np.array(image, dtype='float32')         
    image /= 255.
    image = np.expand_dims(image, axis=0)

    return image

def get_classes(file):
    """Get classes name.

    # Argument:
        file: classes name for database.

    # Returns
        class_names: List, classes name.

    """
    with open(file) as f:
        class_names = f.readlines()
    class_names = [c.strip() for c in class_names]

    return class_names

def draw(image, boxes, scores, classes, all_classes):
    """Draw the boxes on the image.

    # Argument:
        image: original image.
        boxes: ndarray, boxes of objects.
        classes: ndarray, classes of objects.
        scores: ndarray, scores of objects.
        all_classes: all classes name.
    """
    for box, score, cl in zip(boxes, scores, classes):
        x, y, w, h = box

        top = max(0, np.floor(x + 0.5).astype(int))
        left = max(0, np.floor(y + 0.5).astype(int))
        right = min(image.shape[1], np.floor(x + w + 0.5).astype(int))
        bottom = min(image.shape[0], np.floor(y + h + 0.5).astype(int))

        cv2.rectangle(image, (top, left), (right, bottom), (255, 0, 0), 2)
        cv2.putText(image, '{0} {1:.2f}'.format(all_classes[cl], score),
                    (top, left - 6),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6, (0, 0, 255), 1,
                    cv2.LINE_AA)

        print('class: {0}, score: {1:.2f}'.format(all_classes[cl], score))
        print('box coordinate x,y,w,h: {0}'.format(box))
        readyText('class: {0}, score: {1:.2f}'.format(all_classes[cl], score))

    print()

def detect_image(image, yolo, all_classes):
    """Use yolo v3 to detect images.

    # Argument:
        image: original image.
        yolo: YOLO, yolo model.
        all_classes: all classes name.

    # Returns:
        image: processed image.
    """
    pimage = process_image(image)

    start = time.time()
    boxes, classes, scores = yolo.predict(pimage, image.shape)
    end = time.time()

    print('time: {0:.2f}s'.format(end - start))

    if boxes is not None:
        draw(image, boxes, scores, classes, all_classes)
        #print(str(draw(image, boxes, scores, classes, all_classes)).partition('\n')[0])

    return image


yolo = YOLO(0.6, 0.5)
file = 'data/coco_classes.txt'
all_classes = get_classes(file)

    # f = 'puppyyay.jpg'
    # path = 'images/'+f
    # image = cv2.imread(path)
    # image = detect_image(image, yolo, all_classes)
    # cv2.imwrite('images/res/' + f, image)

cap = cv2.VideoCapture(0)
cv2.namedWindow("detection", cv2.WINDOW_AUTOSIZE)
counter = 0
while(True):
    # Capture frame-by-frame
    ret, frame = cap.read()
    # Our operations on the frame come here
    frame = cv2.flip(frame, 1)
    frame_copy = frame.copy()
    if(counter == 5):
        counter = 0
    
    if(counter == 0):
        image = detect_image(frame_copy, yolo, all_classes)
    
    else:
        image = frame_copy
    
    counter+=1

    

    # Display the resulting frame
    cv2.imshow("detection", image)
    sleep(1)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# When everything done, release the capture
cap.release()
cv2.destroyAllWindows()




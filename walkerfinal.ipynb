{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let's see how to use the state of the art in object detection! Please make sure to watch the video, there is no code along here, since we can't reasonably train the YOLOv3 network ourself, instead we will use a pre-established version.\n",
    "\n",
    "CODE SOURCE: https://github.com/xiaochus/YOLOv3\n",
    "\n",
    "REFERENCE (for original YOLOv3): \n",
    "\n",
    "        @article{YOLOv3,  \n",
    "              title={YOLOv3: An Incremental Improvement},  \n",
    "              author={J Redmon, A Farhadi },\n",
    "              year={2018} \n",
    "--------\n",
    "----------\n",
    "-------\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from model.yolo_model import YOLO\n",
    "from time import sleep\n",
    "from google.cloud import texttospeech\n",
    "from google.cloud import texttospeech_v1\n",
    "from playsound import playsound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readyText(text):\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'C:/Users/Rikki/Downloads/Computer-Vision-with-Python/Computer-Vision-with-Python/DATA/blindapp-310321-10ccdaacf88e.json'\n",
    "    client = texttospeech_v1.TextToSpeechClient()\n",
    "    #text = 'Hi my name is Ricky'\n",
    "\n",
    "    synthesis_input = texttospeech_v1.SynthesisInput(text=text)\n",
    "    voice = texttospeech_v1.VoiceSelectionParams(\n",
    "    language_code='en',\n",
    "    ssml_gender=texttospeech_v1.SsmlVoiceGender.MALE\n",
    "    #name=\"en-US-Wavenet-J\",\n",
    "    #language_codes='en-US'\n",
    "    )    \n",
    "    audio_config = texttospeech_v1.AudioConfig(\n",
    "        audio_encoding = texttospeech_v1.AudioEncoding.MP3\n",
    "    )\n",
    "\n",
    "    response = client.synthesize_speech(\n",
    "        input = synthesis_input,\n",
    "        voice = voice,\n",
    "        audio_config = audio_config\n",
    "    )\n",
    "\n",
    "    with open('theaudio.mp3', 'wb') as output:\n",
    "        output.write(response.audio_content)\n",
    "\n",
    "    playsound('C:/Users/Rikki/Downloads/Computer-Vision-with-Python/Computer-Vision-with-Python/06-Deep-Learning-Computer-Vision/06-YOLOv3/theaudio.mp3')\n",
    "    os.remove('C:/Users/Rikki/Downloads/Computer-Vision-with-Python/Computer-Vision-with-Python/06-Deep-Learning-Computer-Vision/06-YOLOv3/theaudio.mp3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    \"\"\"Resize, reduce and expand image.\n",
    "\n",
    "    # Argument:\n",
    "        img: original image.\n",
    "\n",
    "    # Returns\n",
    "        image: ndarray(64, 64, 3), processed image.\n",
    "    \"\"\"\n",
    "    image = cv2.resize(img, (416, 416),\n",
    "                       interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "                       \n",
    "    image = np.array(image, dtype='float32')         \n",
    "    image /= 255.\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(file):\n",
    "    \"\"\"Get classes name.\n",
    "\n",
    "    # Argument:\n",
    "        file: classes name for database.\n",
    "\n",
    "    # Returns\n",
    "        class_names: List, classes name.\n",
    "\n",
    "    \"\"\"\n",
    "    with open(file) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(image, boxes, scores, classes, all_classes):\n",
    "    \"\"\"Draw the boxes on the image.\n",
    "\n",
    "    # Argument:\n",
    "        image: original image.\n",
    "        boxes: ndarray, boxes of objects.\n",
    "        classes: ndarray, classes of objects.\n",
    "        scores: ndarray, scores of objects.\n",
    "        all_classes: all classes name.\n",
    "    \"\"\"\n",
    "    for box, score, cl in zip(boxes, scores, classes):\n",
    "        x, y, w, h = box\n",
    "\n",
    "        top = max(0, np.floor(x + 0.5).astype(int))\n",
    "        left = max(0, np.floor(y + 0.5).astype(int))\n",
    "        right = min(image.shape[1], np.floor(x + w + 0.5).astype(int))\n",
    "        bottom = min(image.shape[0], np.floor(y + h + 0.5).astype(int))\n",
    "\n",
    "        cv2.rectangle(image, (top, left), (right, bottom), (255, 0, 0), 2)\n",
    "        cv2.putText(image, '{0} {1:.2f}'.format(all_classes[cl], score),\n",
    "                    (top, left - 6),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.6, (0, 0, 255), 1,\n",
    "                    cv2.LINE_AA)\n",
    "\n",
    "        print('class: {0}, score: {1:.2f}'.format(all_classes[cl], score))\n",
    "        print('box coordinate x,y,w,h: {0}'.format(box))\n",
    "        theClass = '{0}'.format(all_classes[cl])\n",
    "        theRegion = findRegion(image, top, left, right, bottom)\n",
    "        prox = findSize(image, top, left, right, bottom)\n",
    "        final = 'There is a '+theClass+' in the '+theRegion+' that is '+prox\n",
    "        print(final)\n",
    "        print(findRegion(image, top, left, right, bottom))\n",
    "        readyText(final)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_image(image, yolo, all_classes):\n",
    "    \"\"\"Use yolo v3 to detect images.\n",
    "\n",
    "    # Argument:\n",
    "        image: original image.\n",
    "        yolo: YOLO, yolo model.\n",
    "        all_classes: all classes name.\n",
    "\n",
    "    # Returns:\n",
    "        image: processed image.\n",
    "    \"\"\"\n",
    "    pimage = process_image(image)\n",
    "\n",
    "    start = time.time()\n",
    "    boxes, classes, scores = yolo.predict(pimage, image.shape)\n",
    "    end = time.time()\n",
    "\n",
    "    print('time: {0:.2f}s'.format(end - start))\n",
    "\n",
    "    if boxes is not None:\n",
    "        draw(image, boxes, scores, classes, all_classes)\n",
    "        #print(str(draw(image, boxes, scores, classes, all_classes)).partition('\\n')[0])\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_video(video, yolo, all_classes):\n",
    "    \"\"\"Use yolo v3 to detect video.\n",
    "\n",
    "    # Argument:\n",
    "        video: video file.\n",
    "        yolo: YOLO, yolo model.\n",
    "        all_classes: all classes name.\n",
    "    \"\"\"\n",
    "    video_path = os.path.join(\"videos\", \"test\", video)\n",
    "    camera = cv2.VideoCapture(video_path)\n",
    "    cv2.namedWindow(\"detection\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    # Prepare for saving the detected video\n",
    "    sz = (int(camera.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mpeg')\n",
    "\n",
    "    \n",
    "    vout = cv2.VideoWriter()\n",
    "    vout.open(os.path.join(\"videos\", \"res\", video), fourcc, 20, sz, True)\n",
    "\n",
    "    while True:\n",
    "        res, frame = camera.read()\n",
    "\n",
    "        if not res:\n",
    "            break\n",
    "\n",
    "        image = detect_image(frame, yolo, all_classes)\n",
    "        cv2.imshow(\"detection\", image)\n",
    "\n",
    "        # Save the video frame by frame\n",
    "        vout.write(image)\n",
    "\n",
    "        if cv2.waitKey(110) & 0xff == 27:\n",
    "                break\n",
    "\n",
    "    vout.release()\n",
    "    camera.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO(0.6, 0.5)\n",
    "file = 'data/coco_classes.txt'\n",
    "all_classes = get_classes(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29.80s\n",
      "class: dog, score: 1.00\n",
      "box coordinate x,y,w,h: [ 764.4168148   387.37153959 2374.701828   2566.18217182]\n",
      "There is a dog in the middle right that is close\n",
      "middle right\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = 'puppyyay.jpg'\n",
    "path = 'images/'+f\n",
    "image = cv2.imread(path)\n",
    "image = detect_image(image, yolo, all_classes)\n",
    "cv2.imwrite('images/res/' + f, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSize(img, x, y, w, h):\n",
    "    (W, H) = img.shape[0],img.shape[1]\n",
    "    area = W * H\n",
    "    objArea = w * h\n",
    "    if objArea / area >= 0.5:\n",
    "        return 'close'\n",
    "    elif objArea / area >= 0.3:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'far'\n",
    "def findRegion(img, x, y, w, h):\n",
    "    (W, H) = img.shape[0],img.shape[1]\n",
    "    (centerX, centerY) = (x+(w/2), y+(h/2))\n",
    "    region = ''\n",
    "    if centerX < W/3:\n",
    "        region = region + 'left'\n",
    "    elif centerX < 2*W/3:\n",
    "        region = region + 'middle'\n",
    "    else:\n",
    "        region = region + 'right'\n",
    "    if centerY < H/3:\n",
    "        region = 'top ' + region\n",
    "    elif centerY < 2 * H / 3:\n",
    "        region = 'middle ' + region\n",
    "    else:\n",
    "        region = 'bottom ' + region\n",
    "    if region == 'middle middle':\n",
    "        region = 'center'\n",
    "    return region\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect videos one at a time in videos/test folder    \n",
    "video = ''\n",
    "detect_video(video, yolo, all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.56s\n",
      "time: 7.61s\n",
      "class: person, score: 0.70\n",
      "box coordinate x,y,w,h: [251.85112    221.90494537 101.67886734 203.46209049]\n",
      "There is a person in the bottom right that is close\n",
      "bottom right\n",
      "\n",
      "time: 7.79s\n",
      "time: 7.80s\n",
      "time: 7.84s\n",
      "class: person, score: 0.70\n",
      "box coordinate x,y,w,h: [190.54901123 209.05441761 173.22324753 215.46286583]\n",
      "There is a person in the middle right that is close\n",
      "middle right\n",
      "\n",
      "time: 7.98s\n",
      "time: 8.01s\n",
      "time: 8.05s\n",
      "time: 8.02s\n",
      "class: person, score: 1.00\n",
      "box coordinate x,y,w,h: [116.79619789 208.14376831 277.98002243 216.79654598]\n",
      "There is a person in the center that is close\n",
      "center\n",
      "\n",
      "time: 8.15s\n",
      "class: person, score: 0.98\n",
      "box coordinate x,y,w,h: [143.13367844 232.49763966 241.2537384  184.91875648]\n",
      "There is a person in the bottom right that is close\n",
      "bottom right\n",
      "\n",
      "time: 8.26s\n",
      "time: 8.31s\n",
      "class: person, score: 0.73\n",
      "box coordinate x,y,w,h: [ 44.92977142  50.48140526 539.790802   374.12747383]\n",
      "There is a person in the middle right that is close\n",
      "middle right\n",
      "\n",
      "time: 8.34s\n",
      "time: 8.54s\n",
      "time: 8.53s\n",
      "time: 8.54s\n",
      "time: 8.66s\n",
      "class: person, score: 0.86\n",
      "box coordinate x,y,w,h: [-15.37994385 115.93640327 573.60908508 315.64184189]\n",
      "There is a person in the center that is close\n",
      "center\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"detection\", cv2.WINDOW_AUTOSIZE)\n",
    "counter = 0\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    # Our operations on the frame come here\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_copy = frame.copy()\n",
    "    if(counter == 5):\n",
    "        counter = 0\n",
    "    \n",
    "    if(counter == 0):\n",
    "        image = detect_image(frame_copy, yolo, all_classes)\n",
    "    \n",
    "    else:\n",
    "        image = frame_copy\n",
    "    \n",
    "    counter+=1\n",
    "\n",
    "    \n",
    "\n",
    "    # Display the resulting frame\n",
    "    \n",
    "    cv2.imshow(\"detection\", image)\n",
    "    sleep(1)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
